{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalizer(text): #### Cleaning Tweets\n",
    "    re2 = re.sub(\"[^A-Za-z]+\",\" \", text) # removing numbers\n",
    "    tokens = nltk.word_tokenize(re2)\n",
    "    removed_letters = [word for word in tokens if len(word)>2] # removing words\n",
    "    lower_case = [l.lower() for l in removed_letters]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_result = list(filter(lambda l: l not in stop_words, lower_case))\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = ' '.join([wordnet_lemmatizer.lemmatize(t, pos='v') for t in filtered_result])\n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(train_text,val_text,ngram,thresh):\n",
    "    vectorizer=TfidfVectorizer(analyzer='word',max_features=1500,ngram_range=(ngram),max_df=1.0,min_df=thresh)  \n",
    "    train_vector=vectorizer.fit_transform(train_text)\n",
    "    val_vector=vectorizer.transform(val_text)\n",
    "    return train_vector,val_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(labels):\n",
    "    labels[labels<8]=0\n",
    "    labels[labels>=8]=1\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(df,model,ngram,thresh):\n",
    "    accuracy,f1,precision,recall=[],[],[],[]\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1) \n",
    "    for train_idx,val_idx in kf.split(df):\n",
    "        train=df.iloc[train_idx,:]\n",
    "        val=df.iloc[val_idx,:]\n",
    "        \n",
    "        train_text,train_labels=train['extract'].copy(),label_encode(train['score'].copy())\n",
    "        val_text,val_labels=val['extract'].copy(),label_encode(val['score'].copy())\n",
    "        train_vector,val_vector=extract_features(train_text,val_text,ngram,thresh)\n",
    "        \n",
    "        model.fit(train_vector,train_labels)\n",
    "        y_pred=model.predict(val_vector)\n",
    "        y_pred=y_pred.astype('int')\n",
    "        accuracy.append(accuracy_score(val_labels,y_pred))\n",
    "        f1.append(f1_score(val_labels,y_pred,average='macro'))\n",
    "        precision.append(precision_score(val_labels,y_pred,average='macro'))\n",
    "        recall.append(recall_score(val_labels,y_pred,average='macro'))\n",
    "    \n",
    "    result=pd.DataFrame(data=list(zip(accuracy,precision,recall,f1)),columns=['Accuracy','Precision','Recall','F1-score'])\n",
    "    result.loc['Average'] = result.mean()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_classifier(df):\n",
    "    response=input('Press 0 for Naive Bayers \\n 1 for SVM and 2 for AdaBoost \\n')\n",
    "    if response=='0':\n",
    "        print('Naive Bayes')\n",
    "        model=MultinomialNB()\n",
    "        res1=cross_validation(df,model,ngram=(1,1),thresh=10)\n",
    "        res2=cross_validation(df,model,ngram=(1,2),thresh=20)\n",
    "        res3=cross_validation(df,model,ngram=(1,3),thresh=30)\n",
    "    elif response =='1':\n",
    "        print('Support vector machine')\n",
    "        model=LinearSVC()\n",
    "        res1=cross_validation(df,model,ngram=(1,1),thresh=10)\n",
    "        res2=cross_validation(df,model,ngram=(1,2),thresh=20)\n",
    "        res3=cross_validation(df,model,ngram=(1,3),thresh=30)\n",
    "    elif response=='2':\n",
    "        print('Adaboost classifier')\n",
    "        model=AdaBoostClassifier()\n",
    "        res1=cross_validation(df,model,ngram=(1,1),thresh=10)\n",
    "        res2=cross_validation(df,model,ngram=(1,2),thresh=20)\n",
    "        res3=cross_validation(df,model,ngram=(1,3),thresh=30)\n",
    "    else:\n",
    "        print('wrong button pressed, program terminated')\n",
    "    \n",
    "    return res1,res2,res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,ngram,thresh,vec,clf):\n",
    "    df=pd.read_csv('user_reviews.csv')\n",
    "    labels=df['score']\n",
    "    labels[labels<8]=0\n",
    "    labels[labels>=8]=1\n",
    "    df['extract']=df['extract'].apply(normalizer)\n",
    "    vectorizer=TfidfVectorizer(analyzer='word',max_features=1500,ngram_range=(ngram),max_df=1.0,min_df=thresh)  \n",
    "    data=vectorizer.fit_transform(df['extract'])\n",
    "    joblib.dump(vectorizer,vec)\n",
    "    model.fit(data,labels)\n",
    "    joblib.dump(model,clf)    \n",
    "#save_model(LinearSVC(),(1,1),10,'tfidf.pkl','svm.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df=pd.read_csv('user_reviews.csv')\n",
    "    df['extract']=df['extract'].apply(normalizer)\n",
    "    out1,out2,out3=choose_classifier(df)\n",
    "    return out1.round(2),out2.round(2),out3.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 0 for Naive Bayers \n",
      " 1 for SVM and 2 for AdaBoost \n",
      "0\n",
      "Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out1,out2,out3=main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram\n",
      "         Accuracy  Precision  Recall  F1-score\n",
      "0            0.85       0.84    0.73      0.76\n",
      "1            0.85       0.84    0.73      0.76\n",
      "2            0.85       0.85    0.73      0.76\n",
      "3            0.85       0.85    0.73      0.76\n",
      "4            0.85       0.84    0.73      0.76\n",
      "Average      0.85       0.85    0.73      0.76\n"
     ]
    }
   ],
   "source": [
    "print('bigram')\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram\n",
      "         Accuracy  Precision  Recall  F1-score\n",
      "0            0.85       0.84    0.74      0.77\n",
      "1            0.86       0.84    0.75      0.78\n",
      "2            0.86       0.84    0.75      0.78\n",
      "3            0.85       0.84    0.74      0.78\n",
      "4            0.85       0.84    0.75      0.78\n",
      "Average      0.85       0.84    0.75      0.78\n"
     ]
    }
   ],
   "source": [
    "print('bigram')\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram\n",
      "         Accuracy  Precision  Recall  F1-score\n",
      "0            0.85       0.84    0.74      0.77\n",
      "1            0.86       0.84    0.75      0.78\n",
      "2            0.86       0.84    0.75      0.78\n",
      "3            0.85       0.84    0.75      0.78\n",
      "4            0.85       0.84    0.75      0.78\n",
      "Average      0.85       0.84    0.75      0.78\n"
     ]
    }
   ],
   "source": [
    "print('trigram')\n",
    "print(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
